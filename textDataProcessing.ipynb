{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da29cd8b-5ea8-46c0-87fb-230df7e0262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/anaconda/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Library/anaconda/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/anaconda/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/anaconda/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /Library/anaconda/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1449a8-4239-4603-9a2a-9ad86df4b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a49eca9-8639-462b-b19e-faf48e6f8964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09483255-c529-4c1f-a310-fc44724742d4",
   "metadata": {},
   "source": [
    "# Stemming in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d0ee3c1-e2b5-4f69-908c-fd079e9e5e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change', 'changing', 'changes', 'changed']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "portstm=PorterStemmer()\n",
    "\n",
    "word=['change','changing','changes','changed'] \n",
    "word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c71b989-8823-4f95-96df-59856b401a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change chang\n",
      "changing chang\n",
      "changes chang\n",
      "changed chang\n"
     ]
    }
   ],
   "source": [
    "for w in word:\n",
    "    print(w,portstm.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c66e5b1b-b1b5-40d5-b258-8a2942b83c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen='The goal can vary depending on the context you are asking about.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "651b0cd7-efb7-47a5-89f9-1af4855cf3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The goal can vary depending on the context you are asking about.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fca50b15-def8-45cf-a656-4b7ac6f93095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd48d94-d861-4c85-9b3c-d0fe1c9f0114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'goal',\n",
       " 'can',\n",
       " 'vary',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'the',\n",
       " 'context',\n",
       " 'you',\n",
       " 'are',\n",
       " 'asking',\n",
       " 'about',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "token=word_tokenize(sen)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912d48ec-7d88-4a9b-8a86-545e5c13dd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'goal',\n",
       " 'can',\n",
       " 'vary',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'the',\n",
       " 'context',\n",
       " 'you',\n",
       " 'are',\n",
       " 'asking',\n",
       " 'about.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4adb3e67-f2f6-4514-a01d-f899454c6c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the\n",
      "goal goal\n",
      "can can\n",
      "vary vari\n",
      "depending depend\n",
      "on on\n",
      "the the\n",
      "context context\n",
      "you you\n",
      "are are\n",
      "asking ask\n",
      "about about\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for w in token:\n",
    "    print(w,portstm.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3b0b0-e90b-43e5-8d6d-43f97884e367",
   "metadata": {},
   "source": [
    "# Lemmatization in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96252fc3-b760-41f4-9df6-b0e948cbda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "856a9914-aee2-4742-ab22-7164444cb63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The The\n",
      "goal goal\n",
      "can can\n",
      "vary vary\n",
      "depending depending\n",
      "on on\n",
      "the the\n",
      "context context\n",
      "you you\n",
      "are are\n",
      "asking asking\n",
      "about about\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for w in token:\n",
    "    print(w,wnl.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "630e8082-795c-43cb-9760-fd82d91aa3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "539c4275-8b8b-495a-a18b-227c40c61c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b0f3f-776e-47ec-a3b5-89e970723ead",
   "metadata": {},
   "source": [
    "# Tokenization in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e759ad40-3bc3-4310-af85-795f14be2c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Are', 'you', 'referring', 'to', 'a', 'specific', 'goal', ',', 'like', 'personal', 'growth', ',', 'a', 'project', 'you', \"'re\", 'working', 'on', ',', 'or', 'something', 'more', 'philosophical', 'like', 'the', 'purpose', 'of', 'life', '?', 'Let', 'me', 'know', 'what', 'you', \"'re\", 'thinking', ',', 'and', 'I', 'can', 'help', 'clarify', '!']\n",
      "[\"Are you referring to a specific goal, like personal growth, a project you're working on, or something more philosophical like the purpose of life?\", \"Let me know what you're thinking, and I can help clarify!\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "sen1=\"Are you referring to a specific goal, like personal growth, a project you're working on, or something more philosophical like the purpose of life? Let me know what you're thinking, and I can help clarify!\"\n",
    "wt=word_tokenize(sen1)\n",
    "st=sent_tokenize(sen1)\n",
    "print(wt)\n",
    "print(st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a20bb2fe-5d1a-440c-bf7a-9fb9b4246365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'from', 'aiQuest', 'Intelligence', '.', 'I', 'am', 'learning', 'NLP', '.', 'It', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "sent=\"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
    "doc=nlp(sent)\n",
    "word_tokens = [token.text for token in doc]\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed8cb0e-2887-4c1e-ae0e-f5d424978f87",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62b33531-c01b-465b-ab8f-6bb8add17bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'\", 'm', 'from', 'ai', '##quest', 'intelligence', '.', 'i', 'am', 'learning', 'nl', '##p', '.', 'it', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "sentance=\"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
    "autoToken=tokenizer.tokenize(sentance)\n",
    "print(autoToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd77b35-538f-4604-a071-7a71ce63946a",
   "metadata": {},
   "source": [
    "# Named Entity Tokenization using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c0e1bb2-1303-4813-8467-0944821d2e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/apple/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31b69189-d013-42b5-ae43-d0cee0cd1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86aa215d-9199-453e-b962-c05b00035693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/apple/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /Users/apple/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')  # Download the required resource (NER models)\n",
    "nltk.download('words') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f45610f8-c724-4111-9212-a9920f654ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/apple/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38ab508f-08d4-4982-8870-31d2b0662b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aiQuest Intelligence', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "\n",
    "sentence4 = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\"\n",
    "token = word_tokenize(sentence4)\n",
    "posTag = pos_tag(token)\n",
    "neChunk = ne_chunk(posTag)  # Fixed typo: postTag -> posTag\n",
    "name_entity = []\n",
    "\n",
    "for chunk in neChunk:\n",
    "    if hasattr(chunk, 'label'):  # if statement\n",
    "        name_entity.append(' '.join(c[0] for c in chunk))  # Properly indented block\n",
    "print(name_entity)  # Moved outside the loop to print final result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "07cd1721-4461-436f-b911-e3e3e0806ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/apple/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d28c02-8058-41a8-adf5-3ff989326614",
   "metadata": {},
   "source": [
    "# Text Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239f528b-8970-48c2-b52e-7254cbca1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42fb230-6d53-4017-b19c-bb566cb62a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love Bangladesh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you give me an iphone?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello how are you?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to talk you.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           test  class\n",
       "0             I love Bangladesh      1\n",
       "1  Could you give me an iphone?      0\n",
       "2            Hello how are you?      1\n",
       "3           I want to talk you.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a702a97b-157b-4022-9673-ba50cc8e6ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x2=df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f053dc0e-ae37-4a0c-bd7b-68b385c9fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77232d00-766b-4c59-a09a-fc7620aaa805",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv= CountVectorizer()\n",
    "x1=cv.fit_transform(df['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14214410-afad-4857-8551-e166ec92a097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce40c5c7-842b-4283-bd6b-20d19332fc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['an', 'are', 'bangladesh', 'could', 'give', 'hello', 'how',\n",
       "       'iphone', 'love', 'me', 'talk', 'to', 'want', 'you'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "313bdde7-0a98-423d-beac-c98648809929",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(x1.toarray(),columns=cv.get_feature_names_out(),index=df['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b586e2f4-75a9-4a65-8c3f-7f3107d4369f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>are</th>\n",
       "      <th>bangladesh</th>\n",
       "      <th>could</th>\n",
       "      <th>give</th>\n",
       "      <th>hello</th>\n",
       "      <th>how</th>\n",
       "      <th>iphone</th>\n",
       "      <th>love</th>\n",
       "      <th>me</th>\n",
       "      <th>talk</th>\n",
       "      <th>to</th>\n",
       "      <th>want</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I love Bangladesh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Could you give me an iphone?</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hello how are you?</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I want to talk you.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              an  are  bangladesh  could  give  hello  how  \\\n",
       "test                                                                         \n",
       "I love Bangladesh              0    0           1      0     0      0    0   \n",
       "Could you give me an iphone?   1    0           0      1     1      0    0   \n",
       "Hello how are you?             0    1           0      0     0      1    1   \n",
       "I want to talk you.            0    0           0      0     0      0    0   \n",
       "\n",
       "                              iphone  love  me  talk  to  want  you  \n",
       "test                                                                 \n",
       "I love Bangladesh                  0     1   0     0   0     0    0  \n",
       "Could you give me an iphone?       1     0   1     0   0     0    1  \n",
       "Hello how are you?                 0     0   0     0   0     0    1  \n",
       "I want to talk you.                0     0   0     1   1     1    1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "247d84c1-4059-4287-bcc6-456e649c0bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 16 stored elements and shape (4, 14)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "x=cv.fit_transform(x2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0bce9a0-0bb5-4be1-84f7-fb6722ee47d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08287a02-76b2-46d7-80d4-a866bc09739c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['an', 'are', 'bangladesh', 'could', 'give', 'hello', 'how',\n",
       "       'iphone', 'love', 'me', 'talk', 'to', 'want', 'you'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af67f3b5-8c59-4a5b-a04e-02f284fe3063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>are</th>\n",
       "      <th>bangladesh</th>\n",
       "      <th>could</th>\n",
       "      <th>give</th>\n",
       "      <th>hello</th>\n",
       "      <th>how</th>\n",
       "      <th>iphone</th>\n",
       "      <th>love</th>\n",
       "      <th>me</th>\n",
       "      <th>talk</th>\n",
       "      <th>to</th>\n",
       "      <th>want</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I love Bangladesh</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Could you give me an iphone?</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hello how are you?</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I want to talk you.</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              an  are  bangladesh  could  give  hello  how  \\\n",
       "test                                                                         \n",
       "I love Bangladesh              0    0           1      0     0      0    0   \n",
       "Could you give me an iphone?   1    0           0      1     1      0    0   \n",
       "Hello how are you?             0    1           0      0     0      1    1   \n",
       "I want to talk you.            0    0           0      0     0      0    0   \n",
       "\n",
       "                              iphone  love  me  talk  to  want  you  \n",
       "test                                                                 \n",
       "I love Bangladesh                  0     1   0     0   0     0    0  \n",
       "Could you give me an iphone?       1     0   1     0   0     0    1  \n",
       "Hello how are you?                 0     0   0     0   0     0    1  \n",
       "I want to talk you.                0     0   0     1   1     1    1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=pd.DataFrame(x.toarray(),columns=cv.get_feature_names_out())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af424c92-e248-47c0-b0c4-54ba5cb9a0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 16 stored elements and shape (4, 14)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv=TfidfVectorizer()\n",
    "tvx=tv.fit_transform(x2)\n",
    "tvx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74360b09-1097-43f1-887e-f27ba6b5f3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.70710678, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.43003652, 0.        , 0.        , 0.43003652, 0.43003652,\n",
       "        0.        , 0.        , 0.43003652, 0.        , 0.43003652,\n",
       "        0.        , 0.        , 0.        , 0.27448674],\n",
       "       [0.        , 0.5417361 , 0.        , 0.        , 0.        ,\n",
       "        0.5417361 , 0.5417361 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34578314],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.5417361 , 0.5417361 , 0.5417361 , 0.34578314]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvx.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7079096e-f84a-46e0-afa1-fdbe8be8f8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['an', 'are', 'bangladesh', 'could', 'give', 'hello', 'how',\n",
       "       'iphone', 'love', 'me', 'talk', 'to', 'want', 'you'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7656ebdd-e8d3-414f-9905-a8a5f14d3847",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvxData=pd.DataFrame(tvx.toarray(),columns=tv.get_feature_names_out(), index=df['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f2a35bd9-7e7d-437e-84a9-db63dabb8a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>are</th>\n",
       "      <th>bangladesh</th>\n",
       "      <th>could</th>\n",
       "      <th>give</th>\n",
       "      <th>hello</th>\n",
       "      <th>how</th>\n",
       "      <th>iphone</th>\n",
       "      <th>love</th>\n",
       "      <th>me</th>\n",
       "      <th>talk</th>\n",
       "      <th>to</th>\n",
       "      <th>want</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I love Bangladesh</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Could you give me an iphone?</th>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hello how are you?</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I want to talk you.</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.345783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    an       are  bangladesh     could  \\\n",
       "test                                                                     \n",
       "I love Bangladesh             0.000000  0.000000    0.707107  0.000000   \n",
       "Could you give me an iphone?  0.430037  0.000000    0.000000  0.430037   \n",
       "Hello how are you?            0.000000  0.541736    0.000000  0.000000   \n",
       "I want to talk you.           0.000000  0.000000    0.000000  0.000000   \n",
       "\n",
       "                                  give     hello       how    iphone  \\\n",
       "test                                                                   \n",
       "I love Bangladesh             0.000000  0.000000  0.000000  0.000000   \n",
       "Could you give me an iphone?  0.430037  0.000000  0.000000  0.430037   \n",
       "Hello how are you?            0.000000  0.541736  0.541736  0.000000   \n",
       "I want to talk you.           0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                  love        me      talk        to  \\\n",
       "test                                                                   \n",
       "I love Bangladesh             0.707107  0.000000  0.000000  0.000000   \n",
       "Could you give me an iphone?  0.000000  0.430037  0.000000  0.000000   \n",
       "Hello how are you?            0.000000  0.000000  0.000000  0.000000   \n",
       "I want to talk you.           0.000000  0.000000  0.541736  0.541736   \n",
       "\n",
       "                                  want       you  \n",
       "test                                              \n",
       "I love Bangladesh             0.000000  0.000000  \n",
       "Could you give me an iphone?  0.000000  0.274487  \n",
       "Hello how are you?            0.000000  0.345783  \n",
       "I want to talk you.           0.541736  0.345783  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvxData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bf2cd-9d6c-497c-8227-3d1cc9be09d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
