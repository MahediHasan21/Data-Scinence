{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8dc3422-0dce-4d35-8a2d-3c2425c0d21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc \n",
    "import string \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fcce839-714d-46bd-a68c-542d26bf5c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('email.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81e85d7-a0ad-44cd-a3ca-5062e77d70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column='text'\n",
    "spam_column='spam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a02bc51-bfe9-454b-945c-a48f65d35372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0    4360\n",
       "1    1368\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['spam'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64cdbd7-222b-42bc-9214-e93b93db8a38",
   "metadata": {},
   "source": [
    "# Remove Punctuation and Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95b284a1-fbaf-4627-9e18-e54f122f6373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36486389-0b5e-4239-83e8-6c9aa9a90774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'DaTa'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82b1536b-0bf2-4a56-9966-25008fac8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def text_processing(text):\n",
    "    # Remove punctuation\n",
    "    punctuation_words = [char for char in text if char not in string.punctuation]\n",
    "    clean_words = ''.join(punctuation_words)  # Join the characters back into a string\n",
    "    \n",
    "    # Remove stopwords and convert text to lower case\n",
    "    processed_text = ([word for word in clean_words.split() if word.lower() not in stop_words])\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c05a4e25-bb77-4c88-8a41-121c8907087c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Subject, naturally, irresistible, corporate, ...\n",
       "1       [Subject, stock, trading, gunslinger, fanny, m...\n",
       "2       [Subject, unbelievable, new, homes, made, easy...\n",
       "3       [Subject, 4, color, printing, special, request...\n",
       "4       [Subject, money, get, software, cds, software,...\n",
       "                              ...                        \n",
       "5723    [Subject, research, development, charges, gpg,...\n",
       "5724    [Subject, receipts, visit, jim, thanks, invita...\n",
       "5725    [Subject, enron, case, study, update, wow, day...\n",
       "5726    [Subject, interest, david, please, call, shirl...\n",
       "5727    [Subject, news, aurora, 5, 2, update, aurora, ...\n",
       "Name: text, Length: 5728, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[text_column]=data[text_column].apply(text_processing)\n",
    "data[text_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee449aa-9ceb-4db1-8205-8b7a89c64fa8",
   "metadata": {},
   "source": [
    "# step 2: word lematize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0dfc841-6ae2-4074-9aca-c5d01091a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lematize=WordNetLemmatizer()\n",
    "def lematize_text(text):\n",
    "    word_lematize=''.join(lematize.lemmatize(word)for word in text)\n",
    "    return word_lematize\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c2cfa90-3120-49fb-bc45-d32b47a82eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Subjectnaturallyirresistiblecorporateidentityl...\n",
       "1       Subjectstocktradinggunslingerfannymerrillmuzoc...\n",
       "2       Subjectunbelievablenewhomemadeeasyimwantingsho...\n",
       "3       Subject4colorprintingspecialrequestadditionali...\n",
       "4       Subjectmoneygetsoftwarecdsoftwarecompatibility...\n",
       "                              ...                        \n",
       "5723    Subjectresearchdevelopmentchargegpgforwardedsh...\n",
       "5724    Subjectreceiptvisitjimthanksinvitationvisitlsu...\n",
       "5725    Subjectenroncasestudyupdatewowdaysuperthankmuc...\n",
       "5726    Subjectinterestdavidpleasecallshirleycrenshawa...\n",
       "5727    Subjectnewsaurora52updateauroraversion52fastes...\n",
       "Name: text, Length: 5728, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[text_column]=data[text_column].apply(lematize_text)\n",
    "data[text_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ed74c-d51a-455a-916d-8ba2772e990b",
   "metadata": {},
   "source": [
    "# step3: TF-IDF Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab4e8f70-6748-4672-b2b5-d234ec625cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize=TfidfVectorizer()\n",
    "#x=vectorize.fit_transform(data[text_column])\n",
    "#y=data[spam_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31302322-ad55-48bf-998d-766c27230cd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_vec\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_vec' is not defined"
     ]
    }
   ],
   "source": [
    "x_vec.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853a226-4bab-4ae5-8f4a-fe3cfa6e957f",
   "metadata": {},
   "source": [
    "# Step4: Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ef215-d6cf-4d40-b883-c01e549953ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtrain,xtest,ytarin,ytest=train_test_split(x_vec,y,train_size=0.80,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d7c23-c192-477c-9f27-c19778522d6e",
   "metadata": {},
   "source": [
    "# step5: evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0a2f039-ade2-40d4-b160-acede2279957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB\n",
      "Accuracy score: 0.7428737638161722\n",
      "Confusion Matrix:\n",
      " [[1277    1]\n",
      " [ 441    0]]\n",
      "ROC AUC score: 0.5271603163957289\n",
      "------------------------------\n",
      "Model: BernoulliNB\n",
      "Accuracy score: 0.7347294938917975\n",
      "Confusion Matrix:\n",
      " [[1263   15]\n",
      " [ 441    0]]\n",
      "ROC AUC score: 0.5216404245579296\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score\n",
    "\n",
    "# Define the TfidfVectorizer\n",
    "vectorize = TfidfVectorizer()\n",
    "cv= CountVectorizer()\n",
    "x1=cv.fit_transform(data[text_column])\n",
    "y1=data\n",
    "# Assuming 'data' is your DataFrame and 'text_column' and 'spam_column' are the column names\n",
    "x = vectorize.fit_transform(data[text_column])\n",
    "y = data[spam_column]\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, train_size=0.70, random_state=42)\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB()\n",
    "]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model in models:\n",
    "    model.fit(xtrain, ytrain)  # Train the model\n",
    "    ypred = model.predict(xtest)  # Predict on test data\n",
    "    yprob = model.predict_proba(xtest)[:, 1]  # Get the probability for the positive class\n",
    "\n",
    "    # Print the model type\n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    \n",
    "    # Accuracy score\n",
    "    accuracy = accuracy_score(ytest, ypred)\n",
    "    print(\"Accuracy score:\", accuracy)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(ytest, ypred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # ROC AUC score\n",
    "    roc_auc = roc_auc_score(ytest, yprob)\n",
    "    print(\"ROC AUC score:\", roc_auc)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b14ec1e-9c89-42c9-81fe-7743b0ff6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomtext=input()\n",
    "text_process=text_processing(randomtext)\n",
    "text_lemmitize=lematize_text(text_process)\n",
    "text_vectorise=vectorize.transform([text_lemmitize])\n",
    "\n",
    "for model in models:\n",
    "     prediction=model.predict(text_vectorise)\n",
    "     print(f\"Model: {type(model).__name__}\")\n",
    "     print('predictions: ', prediction)\n",
    "     print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777cd7f-946f-4434-89b6-f13d7656e571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2598e-444f-4143-b93e-6a5e8f181374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
